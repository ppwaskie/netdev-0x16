- Look at what "typical" networking benchmarks look like
	- What's the setup?
	- How do you run it?
	- Why is it so synthentic?
	- CPU power states versus reality

- Can I get a few back-to-back runs going between lucy and pigpen?
	- Try to show 10GbE perf?
	- Look for latency jitter
	- Improve with core affinity
	- Improve with NUMA affinity
	- Improve further with core isolation

- Interrupts can still cause pain
	- NAPI and SOFTIRQ polling will introduce jitter
	- HARDIRQ will also obviously introduce jitter

- Talk about HFT requirements for networking
	- jitter kills more than latency
		- predictability is paramount
	- Exchanges can present different interfaces
		- Different market data protocols
		- Different market network topologies
		- Can be challenging for one-size-fits-all solutions

- How can AF_XDP help?
	- Can it help?
	- Tx is still a big question, with syscall context switch...
	- Very attractive to pursue a "hotpath" and "slowpath" for traffic

- Can we do more?

- Shift to HPC

- Grid networking can have very different latency profiles
	- Message-passing semantics much more common
	- Traditionally more RDMA-based, Infiniband

- Infiniband is still in use, dedicated fabric, lots of existing verb-based SW

- Ethernet-based RDMA technologies still struggling to break through
	- RoCE
		- Needs dedicated links, potentially DCB for no-drop behavior
	- iWARP
		- TOE's are still complex and a black box
		  i.e. non-deterministic latency profiles)

	- Can protocols like HOMA, or Tom Herbert's ideas to merge the best of
	  technologies into an uber stack work?

- Conclusion

Data to try and capture:

- Traditional latency test from lucy to pigpen via 10G (reality)
- irq affinity on lucy latency test (synthetic)
- Load the cores and run the latency test again (synthetic plus reality)
- Isolate the cores and run the latency test again (close to HFT minus irq's)

Flow:

- Introduction

- Traditional networking
	- Benchmarking
	- What does reality look like?
	- How to make it a bit more synthetic (pinning cores, NUMA, etc.)

- Intro to HFT networking
	- What constitutes "high-frequency trading"
	- De-myth about latency
	- Latency is very important, predictable latency is paramount

- Look at the traditional networking benchmarking
	- Now take that to HFT networking profiles (non-isolated cores)
	- Isolate cores, remove scheduler jitter
	- CPU power states vs. complete predictability
	- Next talk about removing context switch jitter (userspace-based stack)

- AF_XDP to the rescue?
	- Can this solve this issue?
	- Tx can still be an issue due to the system call involved
	- Very attractive to pursue a "hotpath" and "slowpath" network pipe
		- Ideal setup.  Have kernel bypass with full stack for control
	- Still need to find a way to poll without NAPI?


- Move to HPC

- Grid networking can have very different latency profiles
	- Message-passing semantics much more common
	- Traditionally more RDMA-based, Infiniband

- Infiniband is still in use, dedicated fabric, lots of existing verb-based SW

- Ethernet-based RDMA technologies still struggling to break through
	- RoCE
		- Needs dedicated links, potentially DCB for no-drop behavior
	- iWARP
		- TOE's are still complex and a black box
		  i.e. non-deterministic latency profiles)

	- Can protocols like HOMA, or Tom Herbert's ideas to merge the best of
	  technologies into an uber stack work?

- Conclusion
	- Deterministic networking performance is paramount to trading
	- Traditional network stack techniques have too much jitter
	- Things like AF_XDP can provide the necessary bypass, but still not
          completely there yet
	- Still need to find a way around NAPI or interrupt-driven Rx processing
          to fully remove jitter
	- Need to revisit for HPC when other protocols make the network stack
	  easier to integrate RDMA-like semantics without Infiniband



Data runs:

Intel(R) Xeon(R) CPU E5-2640 0 @ 2.50GHz

=============================================================================
netperf -H 192.168.100.2 -t TCP_RR -- -o min_latency,max_latency,mean_latency

No optimizations
=============================================================================

Pass 1
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
37,3071,64.42


Pass 2
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
54,458,69.91


Pass 3
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
54,423,69.50


Pass 4
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
54,479,67.40


Pass 5
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
54,471,69.10


Pass 6
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
54,253,72.99


Pass 7
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
53,545,65.99


Pass 8
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
54,380,65.49


Pass 9
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
54,320,70.55


Pass 10
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
48,325,66.80


=============================================================================
netperf -H 192.168.100.2 -T 6 -t TCP_RR -- -o min_latency,max_latency,mean_latency

Pin a CPU, no interrupt affinity
=============================================================================

Pass 1
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
58,581,67.87


Pass 2
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
48,399,64.41


Pass 3
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
49,368,70.98


Pass 4
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
48,351,63.48


Pass 5
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
49,417,68.68


Pass 6
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
53,455,76.50


Pass 7
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
49,505,63.88


Pass 8
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
48,348,64.51


Pass 9
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
49,325,65.51


Pass 10
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
49,502,63.73


=============================================================================
netperf -H 192.168.100.2 -T 6 -t TCP_RR -- -o min_latency,max_latency,mean_latency

Pin a CPU, interrupt affinity
=============================================================================

Pass 1
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
49,614,55.72


Pass 2
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
46,409,54.07


Pass 3
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
45,320,54.08


Pass 4
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
45,499,50.78


Pass 5
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
45,264,53.60


Pass 6
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
45,367,54.00


Pass 7
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
44,391,50.26


Pass 8
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
45,417,53.43


Pass 9
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
46,711,54.13


Pass 10
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
44,485,50.90


=============================================================================
netperf -H 192.168.100.2 -T 6 -t TCP_RR -- -o min_latency,max_latency,mean_latency

Pin a CPU, interrupt affinity, isolate the CPU
=============================================================================


Pass 1
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
51,484,69.03


Pass 2
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
47,319,54.84


Pass 3
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
47,425,66.12


Pass 4
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
49,669,74.71


Pass 5
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
47,1434,56.87


Pass 6
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
48,1902,59.86


Pass 7
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
48,6403,71.90


Pass 8
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
47,340,55.85


Pass 9
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
47,316,58.93


Pass 10
Minimum Latency Microseconds,Maximum Latency Microseconds,Mean Latency Microseconds
47,4357,61.93
